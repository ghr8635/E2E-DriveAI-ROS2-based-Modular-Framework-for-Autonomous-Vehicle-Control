{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.pointpillars import PointPillars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from model.pointpillars import PointPillars\n",
    "import open3d as o3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154581/3101015020.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(pretrained_model_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PointPillars(\n",
       "  (pillar_layer): PillarLayer(\n",
       "    (voxel_layer): Voxelization(\n",
       "      (voxelizer): HardVoxelization()\n",
       "    )\n",
       "  )\n",
       "  (pillar_encoder): PillarEncoder(\n",
       "    (conv): Conv1d(9, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (bn): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (backbone): Backbone(\n",
       "    (multi_blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (13): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (16): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (17): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): Identity()\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming `model` is the PointPillars model\n",
    "pretrained_model_path = \"/home/linux1/ros2_new_ws/src/ams_motor_drive/scripts/epoch_160.pth\"\n",
    "model_state_dict = torch.load(pretrained_model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Initialize the PointPillars model\n",
    "model = PointPillars(\n",
    "    nclasses=3,\n",
    "    voxel_size=[0.16, 0.16, 4],\n",
    "    point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n",
    "    max_num_points=32,\n",
    "    max_voxels=(16000, 40000)  # Training and inference max_voxels\n",
    ")\n",
    "\n",
    "# Load the filtered state dict into the model (without the head weights)\n",
    "model.load_state_dict(model_state_dict, strict=False)\n",
    "\n",
    "# # Now replace the head layer with Identity\n",
    "\n",
    "model.neck = nn.Identity()\n",
    "model.head = nn.Identity()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess PCD file\n",
    "def load_pcd_file(pcd_path):\n",
    "    # Load the point cloud data using Open3D\n",
    "    pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "    # Convert points to numpy array\n",
    "    points = np.asarray(pcd.points)  # (N, 3)\n",
    "\n",
    "    # Check if colors are available and add them\n",
    "    if pcd.has_colors():\n",
    "        colors = np.asarray(pcd.colors)  # (N, 3)\n",
    "        data = np.hstack((points, colors))  # Combine points and colors\n",
    "    else:\n",
    "        data = points  # Only points available\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "# Preprocess the point cloud data for the model\n",
    "def preprocess_point_cloud(pcd_points):\n",
    "    # Assuming the model requires specific preprocessing like voxelization\n",
    "    # Example: Downsample using voxel grid (this is one of many possible approaches)\n",
    "\n",
    "    # For example, voxel size (you may need to tune this)\n",
    "    voxel_size = 0.2\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pcd_points)\n",
    "    downsampled_pcd = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    # Convert the downsampled points to numpy array\n",
    "    downsampled_points = np.asarray(downsampled_pcd.points)  # Shape: (N', 3)\n",
    "\n",
    "    # Convert to torch tensor and add batch dimension\n",
    "    input_tensor = torch.tensor(downsampled_points, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    return input_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def run_inference(input_tensor):\n",
    "    with torch.no_grad():\n",
    "        # Run the model inference (assuming the model returns features directly)\n",
    "        features = model(input_tensor)\n",
    "\n",
    "        #for idx, feature in enumerate(features):\n",
    "            #print(f\"Feature {idx}: Type: {type(feature)}, Shape: {feature.shape if isinstance(feature, torch.Tensor) else 'N/A'}\")\n",
    "        \n",
    "        features = features[-1]      #model provides features on three different scales i.e. at different levels of backbone, last lavel features are more enriched that is why taken. \n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape = torch.Size([1, 25829, 3])\n",
      "ouput tensor shape = torch.Size([1, 3348, 256])\n",
      "Extracted Features: tensor([[[0.1184, 0.0525, 0.0277,  ..., 0.0801, 0.0000, 0.0000],\n",
      "         [0.3384, 0.0878, 0.0000,  ..., 0.0000, 0.1475, 0.0000],\n",
      "         [0.2301, 0.1445, 0.1551,  ..., 0.0000, 0.2247, 0.0000],\n",
      "         ...,\n",
      "         [0.1233, 0.1182, 0.2594,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1127, 0.1336, 0.2213,  ..., 0.0000, 0.0000, 0.0852],\n",
      "         [0.3851, 0.0182, 0.1440,  ..., 0.0000, 0.0570, 0.1720]]])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pcd_path = \"/home/linux1/Desktop/lidar_01__2023-06-02-21-28-09-468.pcd\"\n",
    "pcd_points = load_pcd_file(pcd_path)\n",
    "\n",
    "# Preprocess the point cloud data\n",
    "input_tensor = preprocess_point_cloud(pcd_points)\n",
    "print(f\"input tensor shape = {input_tensor.shape}\")\n",
    "\n",
    "# Run inference\n",
    "features = run_inference(input_tensor)\n",
    "\n",
    "B, C, H, W = features.shape  # B=1, C=256, H=62, W=54\n",
    "\n",
    "# Reshape PointPillars features to [Batch, Seq_Len, Channels]\n",
    "pointpillars_features_flat = features.permute(0, 2, 3, 1).reshape(B, H * W, C)  # [1, 3348, 256]\n",
    "\n",
    "\n",
    "# Output the features (can be used for further processing)\n",
    "print(f\"ouput tensor shape = {pointpillars_features_flat.shape}\")\n",
    "print(\"Extracted Features:\", pointpillars_features_flat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
