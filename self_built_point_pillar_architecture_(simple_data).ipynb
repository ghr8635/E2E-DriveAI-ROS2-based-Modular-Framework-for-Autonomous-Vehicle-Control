{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPX32dM8e9rhMKNilYfUoZJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghr8635/E2E-DriveAI-ROS2-based-Modular-Framework-for-Autonomous-Vehicle-Control/blob/main/self_built_point_pillar_architecture_(simple_data).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCGmgan5fsR5",
        "outputId": "c3d2edd0-9ef7-412d-853a-cd65469209a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lwmxBVkPR2Tc",
        "outputId": "26654868-e623-4765-d7ab-9ecc8df77b52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open3d\n",
            "  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.26.4)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.1.2)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (10.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.8.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.6)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Collecting werkzeug>=2.2.3 (from open3d)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (75.1.0)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.20.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.8.30)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, werkzeug, retrying, pyquaternion, jedi, configargparse, comm, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.2\n",
            "    Uninstalling Werkzeug-3.1.2:\n",
            "      Successfully uninstalled Werkzeug-3.1.2\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 comm-0.2.2 configargparse-1.7 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.1.5 jedi-0.19.2 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4 werkzeug-3.0.6 widgetsnbextension-4.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "ntN1VvWWwgKH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the PointPillars Feature Extraction Model**"
      ],
      "metadata": {
        "id": "_lY8g0e4w1q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PillarFeatureEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_points_per_pillar, grid_x, grid_y):\n",
        "        super(PillarFeatureEncoder, self).__init__()\n",
        "        self.num_points_per_pillar = num_points_per_pillar\n",
        "        self.grid_x, self.grid_y = grid_x, grid_y\n",
        "        # Simple linear layer to encode pillar features\n",
        "        self.fc = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, pillars):\n",
        "        # Flatten and encode features\n",
        "        pillars = self.fc(pillars)  # Shape: (batch, grid_x, grid_y, num_points, out_channels)\n",
        "        return pillars.mean(dim=2)  # Reduce across point dimension to get (batch, grid_x, grid_y, out_channels)\n",
        "\n",
        "class BackboneNetwork(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(BackboneNetwork, self).__init__()\n",
        "        # Simple 2D CNN layers for feature extraction\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.conv3(x)  # Shape: (batch, out_channels, grid_x//4, grid_y//4)\n",
        "        return x\n",
        "\n",
        "class PointPillarsFeatureExtractor(nn.Module):\n",
        "    def __init__(self, in_channels=4, out_channels=256, num_points_per_pillar=32, grid_x=100, grid_y=100):\n",
        "        super(PointPillarsFeatureExtractor, self).__init__()\n",
        "        self.pfe = PillarFeatureEncoder(in_channels, out_channels, num_points_per_pillar, grid_x, grid_y)\n",
        "        self.backbone = BackboneNetwork(out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pillar_features = self.pfe(x)  # Shape: (batch, grid_x, grid_y, out_channels)\n",
        "        pillar_features = pillar_features.permute(0, 3, 1, 2)  # Shape: (batch, out_channels, grid_x, grid_y)\n",
        "        feature_map = self.backbone(pillar_features)\n",
        "        return feature_map"
      ],
      "metadata": {
        "id": "swqyoGh-wtHX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare a Simple Dataset for Training which mimics pcd data**"
      ],
      "metadata": {
        "id": "ZeAKahNPw791"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SyntheticPointCloudDataset(Dataset):\n",
        "    def __init__(self, num_samples, grid_x=100, grid_y=100, num_points_per_pillar=32, in_channels=4):\n",
        "        self.num_samples = num_samples\n",
        "        self.grid_x, self.grid_y = grid_x, grid_y\n",
        "        self.num_points_per_pillar = num_points_per_pillar\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Generate random pillars with shape: (grid_x, grid_y, num_points, in_channels)\n",
        "        pillars = np.random.rand(self.grid_x, self.grid_y, self.num_points_per_pillar, self.in_channels).astype(np.float32)\n",
        "        return torch.tensor(pillars)\n",
        "\n",
        "# Parameters\n",
        "num_samples = 100\n",
        "dataset = SyntheticPointCloudDataset(num_samples)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "Bx6dTsUsw99t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop (Optional, to learn feature extraction patterns)**"
      ],
      "metadata": {
        "id": "hbWR08KDxGN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model, optimizer, and criterion\n",
        "model = PointPillarsFeatureExtractor()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Simple Training Loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    for batch_idx, pillars in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        features = model(pillars)  # Extracted features, shape: (batch, out_channels, grid_x//4, grid_y//4)\n",
        "\n",
        "        # Dummy target: here we're using the output itself as target for demonstration\n",
        "        target = features.clone().detach()  # This is just for illustrative purposes\n",
        "        loss = criterion(features, target)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C4D0rE1xHyR",
        "outputId": "b14f56cd-e3d0-4601-879e-37d78f67d9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [1/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [2/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [3/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [4/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [5/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [6/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [7/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [8/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [9/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [10/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [11/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [12/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [13/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [14/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [15/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [16/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [17/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [18/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [19/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [20/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [21/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [22/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [23/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [24/25], Loss: 0.0000\n",
            "Epoch [1/5], Batch [25/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [1/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [2/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [3/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [4/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [5/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [6/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [7/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [8/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [9/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [10/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [11/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [12/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [13/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [14/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [15/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [16/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [17/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [18/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [19/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [20/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [21/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [22/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [23/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [24/25], Loss: 0.0000\n",
            "Epoch [2/5], Batch [25/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [1/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [2/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [3/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [4/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [5/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [6/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [7/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [8/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [9/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [10/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [11/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [12/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [13/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [14/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [15/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [16/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [17/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [18/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [19/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [20/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [21/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [22/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [23/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [24/25], Loss: 0.0000\n",
            "Epoch [3/5], Batch [25/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [1/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [2/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [3/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [4/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [5/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [6/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [7/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [8/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [9/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [10/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [11/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [12/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [13/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [14/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [15/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [16/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [17/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [18/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [19/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [20/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [21/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [22/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [23/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [24/25], Loss: 0.0000\n",
            "Epoch [4/5], Batch [25/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [1/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [2/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [3/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [4/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [5/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [6/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [7/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [8/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [9/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [10/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [11/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [12/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [13/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [14/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [15/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [16/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [17/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [18/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [19/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [20/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [21/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [22/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [23/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [24/25], Loss: 0.0000\n",
            "Epoch [5/5], Batch [25/25], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving Model**"
      ],
      "metadata": {
        "id": "4NicKX-QxQG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path where you want to save the model\n",
        "model_save_path = \"/content/drive/MyDrive/ROS2-Modular-Framework-for-End-to-End-Autonomous-Vehicle-Control-from-Raw-Sensor-Data/self_built_point_pillar.pth\"\n",
        "\n",
        "# After training is complete, save the model\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl-zBVNjxPwp",
        "outputId": "6aa33f76-4eae-4bbf-ecfd-813c3ce2b279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/ROS2-Modular-Framework-for-End-to-End-Autonomous-Vehicle-Control-from-Raw-Sensor-Data/self_built_point_pillar.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: Upto this point the point pillar based feature extracting model is trained with simply generated dataset and saved. The next part is for inference where a pcd file is processed and provided to the model for inference.**"
      ],
      "metadata": {
        "id": "MnBpqGCdTgm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "\n",
        "# Load the PCD file\n",
        "pcd = o3d.io.read_point_cloud('/content/drive/MyDrive/ROS2-Modular-Framework-for-End-to-End-Autonomous-Vehicle-Control-from-Raw-Sensor-Data/lidar_01__2023-06-02-21-28-09-321.pcd')\n",
        "\n",
        "# Convert the point cloud into a NumPy array (N, 3), where N is the number of points\n",
        "points = np.asarray(pcd.points)\n",
        "\n",
        "print(f\"Loaded point cloud with {points.shape[0]} points\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "y5LQxvwZRPmT",
        "outputId": "6ac3f216-8f01-494f-97bb-da6a1b6d255e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded point cloud with 65536 points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_point_cloud(points, grid_x, grid_y, voxel_size=0.1):\n",
        "    \"\"\"\n",
        "    Convert 3D point cloud to pillar representation.\n",
        "\n",
        "    Args:\n",
        "    - points: (N, 3) numpy array where N is the number of points.\n",
        "    - grid_x: Number of pillars along the X axis.\n",
        "    - grid_y: Number of pillars along the Y axis.\n",
        "    - voxel_size: Size of each voxel (grid cell).\n",
        "\n",
        "    Returns:\n",
        "    - pillars: The preprocessed point cloud as pillar features.\n",
        "    \"\"\"\n",
        "    x_min, y_min = np.min(points[:, 0]), np.min(points[:, 1])\n",
        "    x_max, y_max = np.max(points[:, 0]), np.max(points[:, 1])\n",
        "\n",
        "    # Create grid for the 2D space\n",
        "    grid_x_range = np.linspace(x_min, x_max, grid_x)\n",
        "    grid_y_range = np.linspace(y_min, y_max, grid_y)\n",
        "\n",
        "    # Initialize pillar features\n",
        "    pillars = np.zeros((grid_x, grid_y, 32, 4))  # (grid_x, grid_y, max_points_per_pillar, feature_dim)\n",
        "\n",
        "    for point in points:\n",
        "        # Calculate the 2D grid coordinates for the point\n",
        "        x_idx = int((point[0] - x_min) / voxel_size)\n",
        "        y_idx = int((point[1] - y_min) / voxel_size)\n",
        "\n",
        "        # Ensure indices are within the grid bounds\n",
        "        x_idx = min(x_idx, grid_x - 1)\n",
        "        y_idx = min(y_idx, grid_y - 1)\n",
        "\n",
        "        # Add the point features (x, y, z, intensity) to the pillar\n",
        "        pillar = pillars[x_idx, y_idx]\n",
        "\n",
        "        # If there is an empty space in the pillar (0 entries), insert the point\n",
        "        empty_slot_idx = np.where(pillar[:, 0] == 0)[0]\n",
        "\n",
        "        if len(empty_slot_idx) > 0:\n",
        "            # Fill the first empty slot (use the first one)\n",
        "            pillar_idx = empty_slot_idx[0]\n",
        "            pillars[x_idx, y_idx, pillar_idx] = np.append(point, 1)  # Add intensity as 1 for now\n",
        "        else:\n",
        "            # If no empty slots, replace the point in the pillar (you could add a logic to choose the best point)\n",
        "            pillar_idx = np.argmin(np.linalg.norm(pillar[:, :3], axis=1))  # Choose the point closest to the origin of the pillar\n",
        "            pillars[x_idx, y_idx, pillar_idx] = np.append(point, 1)  # Replace with the new point's features\n",
        "\n",
        "    return pillars\n",
        "\n",
        "# Set grid resolution and voxel size\n",
        "grid_x, grid_y = 100, 100  # Resolution of your grid\n",
        "preprocessed_pillars = preprocess_point_cloud(points, grid_x, grid_y)\n"
      ],
      "metadata": {
        "id": "lSF20KmuSIZ4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Model for Inference**"
      ],
      "metadata": {
        "id": "o3sLSQCsxtRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Initialize the model (assuming you already have the model architecture and weights loaded)\n",
        "model = PointPillarsFeatureExtractor()\n",
        "\n",
        "# Load the saved weights\n",
        "model_save_path = '/content/drive/MyDrive/ROS2-Modular-Framework-for-End-to-End-Autonomous-Vehicle-Control-from-Raw-Sensor-Data/self_built_point_pillar.pth'\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Convert the preprocessed point cloud into a torch tensor\n",
        "input_tensor = torch.tensor(preprocessed_pillars, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Perform inference (no gradient calculation since we're not training)\n",
        "with torch.no_grad():\n",
        "    feature_map = model(input_tensor)\n",
        "\n",
        "# Process the feature_map for your task (if needed)\n",
        "print(\"Feature map extracted:\")\n",
        "print(feature_map.shape)  # Check the output shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_lpH0O1Sb4n",
        "outputId": "0e6029c9-9ae9-4492-8ddb-a4860c85ead2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-c32fd5471caa>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_save_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature map extracted:\n",
            "torch.Size([1, 256, 25, 8])\n"
          ]
        }
      ]
    }
  ]
}