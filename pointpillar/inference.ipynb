{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from model.pointpillars import PointPillars\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PillarFeatureExtractor(nn.Module):\n",
    "    def __init__(self, original_model: PointPillars, fc_dim=512):\n",
    "        super().__init__()\n",
    "        self.pillar_layer = original_model.pillar_layer\n",
    "        self.pillar_encoder = original_model.pillar_encoder\n",
    "        self.backbone = original_model.backbone\n",
    "        self.neck = original_model.neck\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(384, fc_dim)\n",
    "\n",
    "    def forward(self, batched_pts):\n",
    "        timings = {}\n",
    "\n",
    "        start_time = time.time()\n",
    "        pillars, coors_batch, npoints_per_pillar = self.pillar_layer(batched_pts)\n",
    "        timings[\"pillar_layer\"] = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        pillar_features = self.pillar_encoder(pillars, coors_batch, npoints_per_pillar)\n",
    "        timings[\"pillar_encoder\"] = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        xs = self.backbone(pillar_features)\n",
    "        timings[\"backbone\"] = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        feats = self.neck(xs)\n",
    "        timings[\"neck\"] = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        pooled = self.pool(feats)\n",
    "        pooled = pooled.view(pooled.size(0), -1)\n",
    "        timings[\"pooling\"] = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        out_512 = self.fc(pooled)\n",
    "        timings[\"fc\"] = time.time() - start_time\n",
    "\n",
    "        # Print the timing information\n",
    "        for stage, duration in timings.items():\n",
    "            print(f\"{stage}: {duration:.6f} seconds\")\n",
    "\n",
    "        return out_512\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCModel(\n",
       "  (pointpillars): PointPillars(\n",
       "    (pillar_layer): PillarLayer(\n",
       "      (voxel_layer): Voxelization(\n",
       "        (voxelizer): HardVoxelization()\n",
       "      )\n",
       "    )\n",
       "    (pillar_encoder): PillarEncoder(\n",
       "      (conv): Conv1d(9, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (backbone): Backbone(\n",
       "      (multi_blocks): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (8): ReLU(inplace=True)\n",
       "          (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (10): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (11): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (8): ReLU(inplace=True)\n",
       "          (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (11): ReLU(inplace=True)\n",
       "          (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (13): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (14): ReLU(inplace=True)\n",
       "          (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (16): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (17): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (8): ReLU(inplace=True)\n",
       "          (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (11): ReLU(inplace=True)\n",
       "          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (13): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (14): ReLU(inplace=True)\n",
       "          (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (16): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (17): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): Identity()\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=857088, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming `model` is the PointPillars model\n",
    "pretrained_model_path = r\"C:\\Users\\hussa\\OneDrive\\Desktop\\Projects\\ROS2-Modular-Framework-for-End-to-End-Autonomous-Vehicle-Control-from-Raw-Sensor-Data\\poinpillar\\pre_trained\\epoch_160.pth\"\n",
    "model_state_dict = torch.load(pretrained_model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Initialize the PointPillars model\n",
    "model = PointPillars(\n",
    "            nclasses=3,\n",
    "            voxel_size=[0.16, 0.16, 4],\n",
    "            point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n",
    "            max_num_points=32,\n",
    "            max_voxels=(16000, 40000)\n",
    "        )\n",
    "\n",
    "model_state_dict = torch.load(pretrained_model_path, map_location=torch.device('cuda'), weights_only=True)\n",
    "\n",
    "# Load the filtered state dict into the model (without the head weights)\n",
    "model.load_state_dict(model_state_dict, strict=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess PCD file with grayscale intensity\n",
    "def load_pcd_file(pcd_path):\n",
    "    # Load the point cloud data using Open3D\n",
    "    pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "    # Convert points to numpy array\n",
    "    points = np.asarray(pcd.points)  # (N, 3)\n",
    "\n",
    "    # Check if grayscale intensity is available (as colors)\n",
    "    if pcd.has_colors():\n",
    "        # Use one channel (grayscale) from the RGB values\n",
    "        colors = np.asarray(pcd.colors)  # (N, 3)\n",
    "        grayscale_intensity = np.mean(colors, axis=1, keepdims=True)  # Convert RGB to grayscale\n",
    "        data = np.hstack((points, grayscale_intensity))  # Combine points and grayscale intensity\n",
    "    else:\n",
    "        raise ValueError(\"The point cloud does not contain grayscale intensity information.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(point_cloud):\n",
    "    \"\"\"\n",
    "    Reads .pcd with x, y, z + intensity embedded in colors.\n",
    "    Returns a PyTorch tensor of shape [1, N, 4], where N is the number of points.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Directly create the tensor for xyz and intensity\n",
    "    xyz_tensor = torch.tensor(point_cloud[:, :3], dtype=torch.float32).to('cuda')  # Shape: (N, 3)\n",
    "    intensity_tensor = torch.tensor(point_cloud[:, 3], dtype=torch.float32).reshape(-1, 1).to('cuda')  # Shape: (N, 1)\n",
    "\n",
    "    # Remove points with NaN values in xyz or intensity\n",
    "    valid_mask = ~torch.isnan(xyz_tensor).any(dim=1) & ~torch.isnan(intensity_tensor).any(dim=1)\n",
    "    xyz_tensor = xyz_tensor[valid_mask]\n",
    "    intensity_tensor = intensity_tensor[valid_mask]\n",
    "\n",
    "    # Print min and max values for x, y, z\n",
    "    min_x = torch.min(xyz_tensor[:, 0])  # Minimum value in x\n",
    "    min_y = torch.min(xyz_tensor[:, 1])  # Minimum value in y\n",
    "    min_z = torch.min(xyz_tensor[:, 2])  # Minimum value in z\n",
    "    max_x = torch.max(xyz_tensor[:, 0])  # Maximum value in x\n",
    "    max_y = torch.max(xyz_tensor[:, 1])  # Maximum value in y\n",
    "    max_z = torch.max(xyz_tensor[:, 2])  # Maximum value in z\n",
    "\n",
    "    print(f\"Min values - x: {min_x.item()}, y: {min_y.item()}, z: {min_z.item()}\")\n",
    "    print(f\"Max values - x: {max_x.item()}, y: {max_y.item()}, z: {max_z.item()}\")\n",
    "\n",
    "    # Concatenate xyz and intensity tensors directly\n",
    "    points_tensor = torch.cat([xyz_tensor, intensity_tensor], dim=1)  # Shape: (N, 4)\n",
    "\n",
    "    # Add batch dimension to make it [1, N, 4]\n",
    "    points_tensor = points_tensor.unsqueeze(0)  # Shape: (1, N, 4)\n",
    "\n",
    "    return points_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def run_inference(input_tensor):\n",
    "    # Run the model inference\n",
    "        feature_extractor = PillarFeatureExtractor(model).to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            features = feature_extractor(input_tensor)\n",
    "        output = features[0]  \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-31.77777671813965 54.69438552856445 -92.22269439697266 76.7667465209961\n",
      "86.4721622467041 168.98944091796875\n",
      "Input tensor shape: torch.Size([1, 13191, 3])\n",
      "torch.Size([512])\n",
      "fea tensor([-0.0574,  0.1601, -0.0901,  0.1384, -0.1569,  0.0990, -0.1710, -0.1188,\n",
      "        -0.0103, -0.1028, -0.0946,  0.0488,  0.2588,  0.1035, -0.0120,  0.0356,\n",
      "        -0.1061, -0.0077,  0.0708, -0.0990,  0.1504, -0.1407,  0.1077, -0.1237,\n",
      "         0.0226,  0.0868, -0.1475,  0.1259, -0.0586,  0.1449, -0.1752,  0.1087,\n",
      "        -0.1315, -0.1191,  0.0941,  0.1225,  0.0471, -0.2363, -0.2305,  0.0786,\n",
      "         0.1289, -0.0737,  0.0893, -0.0244,  0.1045,  0.0943, -0.0518,  0.0087,\n",
      "         0.2356,  0.0033,  0.2226, -0.0128, -0.0178,  0.0494, -0.1500, -0.0361,\n",
      "         0.1546, -0.0222, -0.0470, -0.1880,  0.1236, -0.0987,  0.0984, -0.1861,\n",
      "        -0.2538,  0.1047, -0.1203,  0.1468, -0.0459,  0.0453,  0.2171,  0.1294,\n",
      "        -0.0155, -0.0333, -0.0396, -0.0988, -0.0179,  0.0145, -0.2498,  0.2064,\n",
      "         0.1072,  0.1592,  0.0925, -0.0174,  0.1009,  0.1306,  0.0222,  0.1918,\n",
      "        -0.0214,  0.1958,  0.0578, -0.1084, -0.0045,  0.0551,  0.0061,  0.0906,\n",
      "         0.0298,  0.0337,  0.2391, -0.0121,  0.0796,  0.0637,  0.0646, -0.0726,\n",
      "         0.0893,  0.0276, -0.1085, -0.1967, -0.1506, -0.0829,  0.0210,  0.2829,\n",
      "         0.0252,  0.1367, -0.1285, -0.1946,  0.0188,  0.1397,  0.0525, -0.2056,\n",
      "         0.0789, -0.1939,  0.0308, -0.0286,  0.0132, -0.3430, -0.1143,  0.0511,\n",
      "        -0.0446,  0.1407, -0.0785, -0.0946, -0.0610,  0.0108, -0.0636,  0.0480,\n",
      "        -0.1675,  0.0222,  0.1837,  0.2051, -0.1528, -0.0216,  0.2465,  0.0387,\n",
      "        -0.0046, -0.0101,  0.0193,  0.0459, -0.0376,  0.0858,  0.1685, -0.0051,\n",
      "        -0.0135,  0.0025, -0.0206, -0.0470,  0.1630,  0.0133,  0.2028, -0.0125,\n",
      "        -0.0306, -0.0474, -0.1080,  0.1473, -0.0332, -0.1827, -0.1241,  0.2484,\n",
      "         0.1596,  0.0419,  0.0756,  0.1675, -0.0379,  0.0811, -0.0900, -0.0524,\n",
      "         0.0115,  0.0284, -0.1898, -0.0897, -0.0511,  0.0509, -0.0538,  0.0399,\n",
      "        -0.0210, -0.0416, -0.2662,  0.0679,  0.1061,  0.1403,  0.1308,  0.0348,\n",
      "         0.1909, -0.1662,  0.1069, -0.1510,  0.1596, -0.0137,  0.3243, -0.0222,\n",
      "        -0.0110,  0.0339,  0.0011, -0.3282, -0.0246,  0.1526, -0.1354, -0.0404,\n",
      "         0.1994,  0.2374, -0.1679, -0.0142, -0.1044, -0.0589, -0.2125, -0.0956,\n",
      "         0.0251,  0.0118,  0.0834, -0.0532,  0.1478, -0.1392, -0.1543,  0.1704,\n",
      "         0.1004,  0.1520, -0.1863,  0.1256,  0.0226, -0.1029,  0.0842, -0.0415,\n",
      "        -0.1041,  0.0503,  0.0678, -0.1055,  0.1544, -0.2077, -0.0639,  0.2155,\n",
      "         0.0929,  0.1099,  0.1095,  0.0320,  0.0425, -0.0579, -0.0093,  0.0028,\n",
      "         0.0630, -0.0331,  0.0689,  0.0698, -0.0510, -0.1344, -0.0653,  0.0528,\n",
      "         0.0774,  0.0998, -0.0925,  0.0072, -0.1758,  0.0383, -0.0492, -0.0617,\n",
      "        -0.1068, -0.2220,  0.0332, -0.0286,  0.0092, -0.0490, -0.0517,  0.0749,\n",
      "        -0.0740,  0.1217, -0.1201,  0.0030, -0.0742, -0.0695,  0.0635,  0.0797,\n",
      "         0.0913, -0.0089,  0.0912,  0.0411,  0.0656,  0.1390, -0.0510,  0.0513,\n",
      "        -0.1590, -0.1698,  0.0582, -0.0404,  0.3263, -0.0051, -0.0604, -0.1441,\n",
      "         0.0091,  0.2344,  0.2109, -0.1681, -0.0180,  0.1006,  0.0429,  0.1025,\n",
      "        -0.0511, -0.0091, -0.2642,  0.0779,  0.0336, -0.1661, -0.0733, -0.1429,\n",
      "        -0.0452,  0.0752,  0.1131, -0.0926,  0.0449,  0.0454,  0.1917, -0.1179,\n",
      "        -0.0968, -0.1147, -0.0833,  0.0437, -0.0032,  0.0210, -0.2133,  0.0847,\n",
      "         0.0042,  0.0931, -0.0117, -0.0746,  0.0018,  0.0270, -0.1564,  0.0338,\n",
      "        -0.2245, -0.0086, -0.2104, -0.1702, -0.0745, -0.0983, -0.1487,  0.0743,\n",
      "        -0.0442, -0.0243, -0.0037, -0.0211,  0.0433, -0.0325,  0.0917,  0.0130,\n",
      "         0.0405,  0.0077,  0.1159, -0.1547,  0.0620,  0.2727,  0.0432,  0.0017,\n",
      "        -0.0721, -0.0622,  0.1262,  0.1691, -0.0804,  0.0051,  0.0477, -0.0878,\n",
      "        -0.0923, -0.0858, -0.0687,  0.1377, -0.0600,  0.0630, -0.1043, -0.0040,\n",
      "         0.1133, -0.0417,  0.1114,  0.1693,  0.0809, -0.0536,  0.1707, -0.0621,\n",
      "        -0.0618, -0.0695,  0.0734,  0.0101, -0.0874,  0.0213,  0.2910, -0.0214,\n",
      "        -0.1074, -0.1087,  0.0873,  0.1386,  0.0996,  0.0429, -0.1324,  0.0937,\n",
      "        -0.1476, -0.0483,  0.0480, -0.1166, -0.0288,  0.1380, -0.0215, -0.0102,\n",
      "        -0.1461, -0.1376, -0.2346, -0.0009,  0.1794,  0.0409,  0.0687,  0.0616,\n",
      "        -0.0716,  0.1450, -0.0034, -0.0179,  0.0925, -0.1428, -0.0102,  0.0952,\n",
      "         0.1530, -0.0383,  0.1869,  0.0738, -0.0143,  0.1057,  0.0147,  0.0084,\n",
      "         0.1693, -0.1512,  0.1143,  0.1537, -0.0496, -0.2506, -0.0214, -0.1191,\n",
      "         0.1240, -0.1503, -0.0332, -0.2163,  0.1117, -0.0501,  0.0603,  0.1711,\n",
      "        -0.0719,  0.0440,  0.1454,  0.1458, -0.0347, -0.1380,  0.1261,  0.2584,\n",
      "        -0.1449, -0.0466,  0.1449, -0.0084,  0.1428,  0.0217, -0.0639, -0.2066,\n",
      "         0.0635,  0.0839, -0.1478,  0.0240,  0.1126,  0.1904, -0.1487,  0.0223,\n",
      "         0.0340, -0.1378,  0.0758, -0.0139, -0.0037,  0.0946, -0.1608,  0.1266,\n",
      "         0.1171,  0.0718, -0.0466, -0.0933, -0.0339, -0.0120,  0.0288,  0.0242,\n",
      "        -0.0665,  0.0228, -0.1832,  0.0257, -0.1415, -0.0677,  0.1164, -0.0782,\n",
      "        -0.1039, -0.0073,  0.1419, -0.0887,  0.0192,  0.0537, -0.1518, -0.0764,\n",
      "        -0.1675, -0.0752,  0.0960,  0.0072, -0.2061, -0.1325,  0.0077,  0.0069])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pcd_path = r\"C:\\Users\\hussa\\Downloads\\rosbag2_2024_10_22-18_21_24_0_pcd_1729614085.243545856.pcd\"\n",
    "points = load_pcd_file(pcd_path)\n",
    "\n",
    "x_min, x_max = np.min(points[:, 0]), np.max(points[:, 0])\n",
    "y_min, y_max = np.min(points[:, 1]), np.max(points[:, 1])\n",
    "\n",
    "print(x_min, x_max, y_min, y_max)\n",
    "x_range = x_max - x_min\n",
    "y_range = y_max - y_min\n",
    "\n",
    "print(x_range, y_range)\n",
    "\n",
    "# Preprocess the point cloud data\n",
    "input_tensor = preprocess_point_cloud(points)\n",
    "\n",
    "# Run inference\n",
    "features = run_inference(input_tensor)\n",
    " \n",
    "print(features.shape)\n",
    "print(f'fea {features}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
